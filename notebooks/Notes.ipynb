{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbb751c9-02f2-41e9-b714-544ffb549f17",
   "metadata": {},
   "source": [
    "# Documentation helper\n",
    "\n",
    "There are three main packages or domains in this solution: \n",
    "\n",
    "* Rules\n",
    "* Dita/XML\n",
    "* LLM\n",
    "\n",
    "Linguistic rules tagging is proposed to verify the validity of the generated manual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc43402a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install -qU \"langchain[aws]\" python-dotenv lxml atlassian-python-api\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c770c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "# Configure the Bedrock client with a read timeout of 3600 seconds\n",
    "config = Config(read_timeout=3600, region_name=\"us-east-1\")\n",
    "\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", config=config)\n",
    "\n",
    "with open(\"json/rules.json\") as file:\n",
    "    rules = file.read()\n",
    "\n",
    "with open(\"json/bad_words.json\") as file:\n",
    "    bad_words = file.read()\n",
    "\n",
    "def base_prompt(job, rules, bad_words, instructions): return f\"\"\"Your job is to {job} based on the following\n",
    "Rules:\n",
    "{rules}\n",
    "\n",
    "Forbidden words:\n",
    "{bad_words}\n",
    "\n",
    "Instructions:\n",
    "{instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bfb9b86",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'txt/PMD_PRISM.IO_Digital_IO_Management.docx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bedrock_client.converse(\n\u001b[32m     48\u001b[39m         modelId=model_id,\n\u001b[32m     49\u001b[39m         system=[{\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: system_role}],\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m         ]\n\u001b[32m     59\u001b[39m     )\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# except (ClientError, Exception) as e:\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtxt/PMD_PRISM.IO_Digital_IO_Management.docx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m     65\u001b[39m     manual = file.read()\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_corrected_dita\u001b[39m(*args):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/docu/lib/python3.12/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'txt/PMD_PRISM.IO_Digital_IO_Management.docx'"
     ]
    }
   ],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class DocumentType(str, Enum):\n",
    "    HTML = \"html\"\n",
    "    MARKDOWN = \"md\"\n",
    "    PDF = \"pdf\"\n",
    "    DOCX = \"docx\"\n",
    "    DOC = \"doc\"\n",
    "    XLSX = \"xlsx\"\n",
    "    XLS = \"xls\"\n",
    "    CSV = \"csv\"\n",
    "    TXT = \"txt\"\n",
    "\n",
    "\n",
    "async def generate_dita(document: bytes, file_name: str, rules: str, bad_words: str, model_id: str, document_type: DocumentType = DocumentType.TXT):\n",
    "\n",
    "    instructions = \"\"\"\n",
    "    - Check the document for compliance with the provided rules.\n",
    "    - Identify any violations of the rules.\n",
    "    - Suggest corrections for the identified violations.\n",
    "    - Ensure the output is in DITA format.\n",
    "\n",
    "    Answer only in DITA format, without any additional text or explanations. If needed, do multiple files to cover all content.\n",
    "    \"\"\"\n",
    "\n",
    "    system_role = f\"You are a technical editor that generates dita files based on given rules.\\n\\n{base_prompt(job='generate DITA file', rules=rules, bad_words=bad_words, instructions=instructions)}\"\n",
    "\n",
    "    document_reference = {\n",
    "        \"format\": document_type,\n",
    "        \"name\": file_name,\n",
    "        \"source\": {\n",
    "            \"bytes\": document,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    user_prompt = \"Read the document and generate the DITA file with the necessary corrections based on the provided rules and forbidden words.\"\n",
    "\n",
    "    inference_config = {\n",
    "        \"temperature\": 0.2,\n",
    "        \"system\": system_role,\n",
    "        \"max_tokens\": 5000,\n",
    "    }\n",
    "\n",
    "    return bedrock_client.converse(\n",
    "        modelId=model_id,\n",
    "        system=[{\"text\": system_role}],\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                        {\"text\": user_prompt},\n",
    "                        {\"document\": document_reference}\n",
    "                ]   \n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # except (ClientError, Exception) as e:\n",
    "    # print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "\n",
    "with open(\"txt/PMD_PRISM.IO_Digital_IO_Management.docx\", \"rb\") as file:\n",
    "    manual = file.read()\n",
    "\n",
    "async def generate_corrected_dita(*args):\n",
    "    pass\n",
    "\n",
    "print(\"Generating response\")\n",
    "resp = await generate_corrected_dita(manual, \"IO Digital IO Management\", rules, bad_words, \"arn:aws:bedrock:us-east-1:473326111529:inference-profile/us.anthropic.claude-sonnet-4-20250514-v1:0\", DocumentType.DOCX)\n",
    "\n",
    "usage = resp[\"usage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6934233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating response\n"
     ]
    }
   ],
   "source": [
    "async def correct_dita(document: str, file_name: str, rules: str, bad_words: str, model_id: str):\n",
    "    \"\"\"\n",
    "    Generate a corrected DITA file based on the provided document and rules.\n",
    "\n",
    "    Args:\n",
    "        document (bytes): The document content to be processed.\n",
    "        file_name (str): The name of the file being processed.\n",
    "        rules (str): The rules to check against.\n",
    "        bad_words (str): The forbidden words to avoid.\n",
    "        model_id (str): The model ID for the inference.\n",
    "        document_type (DocumentType): The type of the document.\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from the Bedrock client.\n",
    "    \"\"\"\n",
    "    instructions = \"\"\"\n",
    "    - Modify the text only when necessary.\n",
    "    - Mark all corrections using the following syntax:\n",
    "        - ~~Original~~ â†’ **Corrected** (Reason)\n",
    "    - Do not add new sections unless explicitly required.\"\"\"\n",
    "\n",
    "    system_role = f\"You are a technical editor that verifies dita files based on given rules.\\n\\n{base_prompt(job='corrects DITA file', rules=rules, bad_words=bad_words, instructions=instructions)}\"\n",
    "    user_prompt = \"Read the document and correct it based on the provided rules and forbidden words.\"\n",
    "    inference_config = {\n",
    "        \"temperature\": 0.2,\n",
    "        \"system\": system_role,\n",
    "        \"max_tokens\": 5000,\n",
    "    }\n",
    "    return bedrock_client.converse(\n",
    "        modelId=model_id,\n",
    "        system=[{\"text\": system_role}],\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"text\": user_prompt},\n",
    "                    {\"text\": document}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    \n",
    "with open(\"dita/parameters.dita\") as file:\n",
    "    dita = file.read()\n",
    "\n",
    "print(\"Generating response\")\n",
    "resp = await correct_dita(dita, \"parameters.dita\", rules, bad_words, \"arn:aws:bedrock:us-east-1:473326111529:inference-profile/us.anthropic.claude-sonnet-4-20250514-v1:0\")\n",
    "\n",
    "usage = resp[\"usage\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5260ab",
   "metadata": {},
   "source": [
    "## BitBucket connector\n",
    "\n",
    "This connector is essential to get the dita files and publish changes through pull requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c82503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlassian import Bitbucket\n",
    "import os\n",
    "\n",
    "connector = Bitbucket(\n",
    "    url=os.getenv(\"BITBUCKET_URL\"),\n",
    "    username=os.getenv(\"BITBUCKET_USERNAME\"),\n",
    "    password=os.getenv(\"BITBUCKET_PASSWORD\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6eb27e-86d8-45d1-9e96-bf9832f763ad",
   "metadata": {},
   "source": [
    "## XML/DITA Parser\n",
    "\n",
    "This parser will have the responsibility to extract and validate the dita syntax, although the validation part could already be performed by the technical writer if he is using oxygen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55ad01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "ROOT_TAGS = [\"concept\", \"topic\", \"task\", \"reference\", \"glossentry\"]\n",
    "ERRORS, WARNINGS = [], []\n",
    "\n",
    "def prettyprint(element, **kwargs):\n",
    "    xml = etree.tostring(element, pretty_print=True, **kwargs)\n",
    "    print(xml.decode(), end='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad2f0c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse the DITA file\n",
    "tree = etree.parse(\"./docs/accessing_the_device.dita\")\n",
    "root = tree.getroot()\n",
    "\n",
    "# First check: root tag should be in any of the initial root tags, if not. Show warning\n",
    "if root.tag not in ROOT_TAGS:\n",
    "    print(f\"Warning: Root tag '{root.tag}' is not in the list of allowed root tags: {ROOT_TAGS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f01dea88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"errors\": [],\n",
      "  \"warnings\": [],\n",
      "  \"summary\": {\n",
      "    \"error_count\": 0,\n",
      "    \"warning_count\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import sys, json, argparse, pathlib, re\n",
    "from lxml import etree\n",
    "from enum import Enum\n",
    "import yaml\n",
    "\n",
    "ERRORS, WARNINGS = [], []\n",
    "\n",
    "class IssueSeverity(str, Enum):\n",
    "    ERROR = \"ERROR\"\n",
    "    WARN = \"WARN\"\n",
    "\n",
    "def add_issue(sev: IssueSeverity, file, line, code, msg):\n",
    "    entry = {\"severity\": sev, \"file\": str(file), \"line\": line, \"code\": code, \"message\": msg}\n",
    "    (ERRORS if sev==IssueSeverity.ERROR else WARNINGS).append(entry)\n",
    "\n",
    "def well_formed(path: pathlib.Path):\n",
    "    try:\n",
    "        etree.parse(str(path))\n",
    "        return True\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        add_issue(IssueSeverity.ERROR, path, getattr(e, 'position', (None,))[0], \"XML_NOT_WELLFORMED\", str(e))\n",
    "        return False\n",
    "\n",
    "def check_href_exists(doc_path, tree, docs_root):\n",
    "    # href on elements like <xref> <image> <link> etc.\n",
    "    for el in tree.xpath('//*[@href]'):\n",
    "        href = el.get(\"href\")\n",
    "        if not href or re.match(r'^\\w+://', href):  # skip external\n",
    "            continue\n",
    "        target = (doc_path.parent / href).resolve()\n",
    "        # prevent escaping docs root\n",
    "        if docs_root not in target.parents and target != docs_root:\n",
    "            add_issue(IssueSeverity.ERROR, doc_path, el.sourceline, \"PATH_ESCAPE\", f\"path escapes docs root: {href}\")\n",
    "            continue\n",
    "        if '#' in href:\n",
    "            file_part, frag = href.split('#', 1)\n",
    "            target_file = (doc_path.parent / file_part).resolve()\n",
    "            if not target_file.exists():\n",
    "                add_issue(IssueSeverity.ERROR, doc_path, el.sourceline, \"MISSING_TARGET\", f\"file not found: {file_part}\")\n",
    "                continue\n",
    "            try:\n",
    "                ttree = etree.parse(str(target_file))\n",
    "            except Exception:\n",
    "                add_issue(IssueSeverity.ERROR, doc_path, el.sourceline, \"TARGET_NOT_XML\", f\"target not parseable: {file_part}\")\n",
    "                continue\n",
    "            if not ttree.xpath(f\"//*[@id='{frag}']\"):\n",
    "                add_issue(IssueSeverity.ERROR, doc_path, el.sourceline, \"MISSING_FRAGMENT\", f\"#{frag} not found in {file_part}\")\n",
    "        else:\n",
    "            if not target.exists():\n",
    "                add_issue(IssueSeverity.ERROR, doc_path, el.sourceline, \"MISSING_TARGET\", f\"file not found: {href}\")\n",
    "\n",
    "def is_svg(path: pathlib.Path) -> bool:\n",
    "    return path.suffix.lower() == \".svg\"\n",
    "\n",
    "def sniff_svg(path: pathlib.Path) -> bool:\n",
    "    try:\n",
    "        tree = etree.parse(str(path))\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        add_issue(IssueSeverity.ERROR, path, getattr(e, 'position', (None,))[0], \"SVG_NOT_WELLFORMED\", str(e))\n",
    "        return False\n",
    "    root = tree.getroot()\n",
    "    if root.tag.lower().endswith(\"svg\") is False:\n",
    "        add_issue(IssueSeverity.ERROR, path, 1, \"SVG_ROOT_INVALID\", \"root element is not <svg>\")\n",
    "        return False\n",
    "    # disallow scripts and external refs\n",
    "    for bad in root.xpath('.//script|.//*[@href or @xlink:href]'):\n",
    "        href = bad.get('href') or bad.get('{http://www.w3.org/1999/xlink}href')\n",
    "        if bad.tag.endswith('script'):\n",
    "            add_issue(IssueSeverity.ERROR, path, bad.sourceline, \"SVG_SCRIPT_FORBIDDEN\", \"<script> not allowed\")\n",
    "        elif href and re.match(r'^\\w+://', href):\n",
    "            add_issue(IssueSeverity.WARN, path, bad.sourceline, \"SVG_EXTERNAL_REF_FORBIDDEN\", f\"external ref: {href}\")\n",
    "    # viewBox/size\n",
    "    if not (root.get('viewBox') or (root.get('width') and root.get('height'))):\n",
    "        add_issue(IssueSeverity.WARN, path, 1, \"SVG_DIMENSIONS_WEAK\", \"missing viewBox and dimensions\")\n",
    "    return True\n",
    "\n",
    "def walk_and_validate(cfg):\n",
    "    docs_root = pathlib.Path(cfg['docs_root']).resolve()\n",
    "    for xml in docs_root.rglob(\"*.dita\"):\n",
    "        validate_single(xml, docs_root)\n",
    "    for xml in docs_root.rglob(\"*.xml\"):\n",
    "        validate_single(xml, docs_root)\n",
    "    # image sweep (including non-referenced in v1)\n",
    "    for img in docs_root.rglob(\"*.svg\"):\n",
    "        sniff_svg(img)\n",
    "\n",
    "def validate_single(path, docs_root):\n",
    "    if not well_formed(path):\n",
    "        return\n",
    "    tree = etree.parse(str(path))\n",
    "    check_href_exists(path, tree, docs_root)\n",
    "    # (Optional) hook: DTD/RNG/Schematron validation here\n",
    "\n",
    "def main():\n",
    "    cfg = yaml.safe_load(open(\"config.yaml\"))\n",
    "    walk_and_validate(cfg)\n",
    "    report = {\"errors\": ERRORS, \"warnings\": WARNINGS, \"summary\": {\n",
    "        \"error_count\": len(ERRORS), \"warning_count\": len(WARNINGS)}}\n",
    "    print(json.dumps(report, indent=2))\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
